# VQA From Scratch (Visual Question Answering)

> **Status:** Developing (Sprint 1)  
> **Author:** [TÃªn Cá»§a Báº¡n]  
> **Environment:** Omarchy (Arch Linux) | PyTorch | CUDA  

Dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng AI cÃ³ kháº£ nÄƒng tráº£ lá»i cÃ¢u há»i dá»±a trÃªn hÃ¬nh áº£nh (VQA), phÃ¡t triá»ƒn tá»« con sá»‘ 0 Ä‘á»ƒ phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p chuyÃªn sÃ¢u (Deep Learning, NLP, CV).

## Má»¥c TiÃªu (Goals)

1.  **Hiá»ƒu sÃ¢u báº£n cháº¥t:** Tá»± code cÃ¡c module cá»‘t lÃµi (LSTM, Attention, CNN Pipeline) thay vÃ¬ dÃ¹ng thÆ° viá»‡n Äƒn sáºµn.
2.  **Kiáº¿n trÃºc linh hoáº¡t:** XÃ¢y dá»±ng há»‡ thá»‘ng theo dáº¡ng Module Ä‘á»ƒ dá»… dÃ ng nÃ¢ng cáº¥p tá»« Simple Model lÃªn Attention Model.
3.  **Generative VQA:** Model pháº£i *sinh ra* cÃ¢u tráº£ lá»i (Open-ended generation) thay vÃ¬ chá»‰ chá»n tá»« táº­p Ä‘Ã³ng (Classification).

---

## Development Roadmap (Scrum Board)

### Phase 1: The Foundation (Data Pipeline)
*Má»¥c tiÃªu: Dá»¯ liá»‡u cháº£y thÃ´ng suá»‘t tá»« Raw -> Tensor -> DataLoader.*
- [ ] **Task 1.1:** Setup project structure (Folder, Symlinks).
- [ ] **Task 1.2:** Viáº¿t Module Vocabulary (`src/vocab.py`) xá»­ lÃ½ cáº£ Question & Answer.
- [ ] **Task 1.3:** Viáº¿t Script Preprocessing (`scripts/1_build_vocab.py`).
- [ ] **Task 1.4:** Viáº¿t Script Feature Extraction (`scripts/2_extract_features.py`) - LÆ°u tensor 3D (14x14).
- [ ] **Task 1.5:** Viáº¿t Dataset Class (`src/dataset.py`) ghÃ©p ná»‘i táº¥t cáº£.

### Phase 2: The Prototype (Simple LSTM)
*Má»¥c tiÃªu: "Walking Skeleton" - Model cháº¡y Ä‘Æ°á»£c, loss giáº£m, chÆ°a cáº§n thÃ´ng minh.*
- [ ] **Task 2.1:** Viáº¿t Image Encoder (Flatten features).
- [ ] **Task 2.2:** Viáº¿t Question Encoder (LSTM).
- [ ] **Task 2.3:** Viáº¿t Decoder Ä‘Æ¡n giáº£n (Concat Image + Question -> LSTM).
- [ ] **Task 2.4:** Training Loop v1 (Overfit trÃªn 1 batch nhá» Ä‘á»ƒ test code).

### Phase 3: The Intelligence (Attention Mechanism)
*Má»¥c tiÃªu: Model biáº¿t "nhÃ¬n" vÃ o Ä‘Ã¢u khi tráº£ lá»i.*
- [ ] **Task 3.1:** Implement Soft Attention Module.
- [ ] **Task 3.2:** NÃ¢ng cáº¥p Decoder Ä‘á»ƒ tÃ­ch há»£p Attention.
- [ ] **Task 3.3:** Training trÃªn full dataset.
- [ ] **Task 3.4:** Evaluation (BLEU Score, Accuracy).

---

## ğŸ› ï¸ Architecture Overview

### 1. Data Flow
`Raw Images` -> **ResNet101** -> `Visual Features (14x14x2048)`  
`Questions` -> **Tokenizer** -> `Indices Tensor`  
`Answers` -> **Tokenizer** -> `Indices Tensor`

### 2. Model Design (Attention Variant)
* **Image Encoder:** ResNet-101 (Pretrained, remove last FC).
* **Question Encoder:** Embedding + LSTM (2 layers).
* **Fusion:** Soft Attention (Bahdanau Style).
* **Decoder:** LSTM Generator (Word-by-word generation).

---

## Project Structure

```text
vqa_scratch/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Symlinks tá»›i COCO & VQA Dataset gá»‘c
â”‚   â”œâ”€â”€ processed/          # Chá»©a vocab.json, features.h5
â”œâ”€â”€ src/                    # Source code chÃ­nh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vocab.py            # Xá»­ lÃ½ ngÃ´n ngá»¯
â”‚   â”œâ”€â”€ dataset.py          # PyTorch Dataset
â”‚   â”œâ”€â”€ model.py            # Äá»‹nh nghÄ©a kiáº¿n trÃºc Neural Net
â”œâ”€â”€ scripts/                # Scripts cháº¡y 1 láº§n (Data prep)
â”‚   â”œâ”€â”€ 1_build_vocab.py
â”‚   â”œâ”€â”€ 2_extract_features.py
â”œâ”€â”€ checkpoints/            # LÆ°u model weights
â””â”€â”€ DEV_LOG.md              # Nháº­t kÃ½ phÃ¡t triá»ƒn chi tiáº¿t
