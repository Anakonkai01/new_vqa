{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c79e5d",
   "metadata": {},
   "source": [
    "# Visual Question Answering — End-to-End Pipeline\n",
    "\n",
    "**Bài toán:** Cho ảnh + câu hỏi → sinh câu trả lời bằng LSTM-Decoder.\n",
    "\n",
    "**4 kiến trúc:**\n",
    "\n",
    "| Model | CNN Encoder | Attention |\n",
    "|-------|-------------|----------|\n",
    "| A | Scratch CNN | No |\n",
    "| B | Pretrained ResNet101 | No |\n",
    "| C | Scratch CNN | Bahdanau |\n",
    "| D | Pretrained ResNet101 | Bahdanau |\n",
    "\n",
    "**Pipeline:**\n",
    "1. Clone repo + cài đặt dependencies\n",
    "2. Tải dữ liệu VQA 2.0 từ Kaggle\n",
    "3. Build vocab (questions + answers)\n",
    "4. Train 4 models (A, B, C, D)\n",
    "5. Plot training curves\n",
    "6. Evaluate từng model (VQA Accuracy, Exact Match, BLEU-1/2/3/4, METEOR)\n",
    "7. So sánh 4 models side-by-side\n",
    "8. Inference trên sample\n",
    "9. Attention Visualization (Model C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b83d0",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0 — Environment Setup\n",
    "\n",
    "- Kiểm tra GPU\n",
    "- Clone repository từ GitHub\n",
    "- Cài đặt dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20779874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/Anakonkai01/new_vqa.git\n",
    "%cd new_vqa\n",
    "\n",
    "# Checkout branch (thay đổi nếu cần)\n",
    "!git checkout experiment/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt dependencies\n",
    "!pip install -q nltk tqdm matplotlib Pillow\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ad651",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 — Download VQA 2.0 Data từ Kaggle\n",
    "\n",
    "Tải 3 datasets:\n",
    "- **vqa-20-images**: COCO train2014 images\n",
    "- **vqa-2-0-val2014**: COCO val2014 images\n",
    "- **vqa2-0-data-json**: VQA 2.0 question + annotation JSON files\n",
    "\n",
    "> **Note:** Cần cấu hình Kaggle API key trước (upload `kaggle.json` hoặc set biến môi trường)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdcf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nếu chưa có kaggle.json, upload nó:\n",
    "# from google.colab import files\n",
    "# files.upload()  # upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu từ Kaggle\n",
    "!kaggle datasets download -d bishoyabdelmassieh/vqa-20-images -p datasets --unzip\n",
    "!kaggle datasets download -d hongnhnnguyntrn/vqa-2-0-val2014 -p datasets --unzip\n",
    "!kaggle datasets download -d hongnhnnguyntrn/vqa2-0-data-json -p datasets --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca3f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra cấu trúc dataset đã tải\n",
    "import os\n",
    "print(\"Downloaded files:\")\n",
    "for root, dirs, files in os.walk('datasets'):\n",
    "    level = root.replace('datasets', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    if level < 2:  # chỉ hiện 2 levels đầu\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for f in files[:5]:\n",
    "            print(f\"{subindent}{f}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... ({len(files)} files total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b09220",
   "metadata": {},
   "source": [
    "### Sắp xếp dữ liệu vào đúng cấu trúc thư mục project\n",
    "\n",
    "Project yêu cầu cấu trúc:\n",
    "```\n",
    "data/raw/images/train2014/   ← COCO train images\n",
    "data/raw/images/val2014/     ← COCO val images  \n",
    "data/raw/vqa_json/           ← VQA 2.0 JSON files\n",
    "data/processed/              ← vocab files (sẽ được tạo ở step sau)\n",
    "```\n",
    "\n",
    "> **Quan trọng:** Cell dưới sẽ tạo symlinks/move dữ liệu vào đúng vị trí. Hãy kiểm tra output của cell trên để xác nhận đường dẫn chính xác, nếu cấu trúc Kaggle khác thì sửa lại cell dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "\n",
    "# Tạo thư mục đích\n",
    "os.makedirs('data/raw/images', exist_ok=True)\n",
    "os.makedirs('data/raw/vqa_json', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# ── Helper: tìm thư mục chứa COCO images ─────────────────────────────\n",
    "def find_coco_dir(base, split):\n",
    "    \"\"\"Tìm thư mục chứa ảnh COCO_<split>_*.jpg trong base.\"\"\"\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        for f in files:\n",
    "            if f.startswith(f'COCO_{split}_') and f.endswith('.jpg'):\n",
    "                return root\n",
    "    return None\n",
    "\n",
    "# ── Symlink train2014 images ──────────────────────────────────────────\n",
    "train_dir = find_coco_dir('datasets', 'train2014')\n",
    "if train_dir and not os.path.exists('data/raw/images/train2014'):\n",
    "    os.symlink(os.path.abspath(train_dir), 'data/raw/images/train2014')\n",
    "    print(f\"Linked train2014: {train_dir} -> data/raw/images/train2014\")\n",
    "elif os.path.exists('data/raw/images/train2014'):\n",
    "    print(\"train2014 already exists.\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find train2014 images in datasets/\")\n",
    "\n",
    "# ── Symlink val2014 images ────────────────────────────────────────────\n",
    "val_dir = find_coco_dir('datasets', 'val2014')\n",
    "if val_dir and not os.path.exists('data/raw/images/val2014'):\n",
    "    os.symlink(os.path.abspath(val_dir), 'data/raw/images/val2014')\n",
    "    print(f\"Linked val2014: {val_dir} -> data/raw/images/val2014\")\n",
    "elif os.path.exists('data/raw/images/val2014'):\n",
    "    print(\"val2014 already exists.\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find val2014 images in datasets/\")\n",
    "\n",
    "# ── Copy VQA JSON files ───────────────────────────────────────────────\n",
    "json_patterns = [\n",
    "    'v2_OpenEnded_mscoco_train2014_questions.json',\n",
    "    'v2_OpenEnded_mscoco_val2014_questions.json',\n",
    "    'v2_mscoco_train2014_annotations.json',\n",
    "    'v2_mscoco_val2014_annotations.json',\n",
    "]\n",
    "for jname in json_patterns:\n",
    "    dst = f'data/raw/vqa_json/{jname}'\n",
    "    if os.path.exists(dst):\n",
    "        print(f\"  Already exists: {dst}\")\n",
    "        continue\n",
    "    # Tìm file trong datasets/\n",
    "    matches = glob.glob(f'datasets/**/{jname}', recursive=True)\n",
    "    if matches:\n",
    "        shutil.copy2(matches[0], dst)\n",
    "        print(f\"  Copied: {matches[0]} -> {dst}\")\n",
    "    else:\n",
    "        print(f\"  WARNING: {jname} not found in datasets/\")\n",
    "\n",
    "# ── Verify ────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- Verification ---\")\n",
    "for p in ['data/raw/images/train2014', 'data/raw/images/val2014']:\n",
    "    if os.path.exists(p):\n",
    "        n = len(os.listdir(p))\n",
    "        print(f\"  {p}: {n:,} files\")\n",
    "    else:\n",
    "        print(f\"  MISSING: {p}\")\n",
    "for p in json_patterns:\n",
    "    full = f'data/raw/vqa_json/{p}'\n",
    "    sz = os.path.getsize(full) / 1e6 if os.path.exists(full) else 0\n",
    "    print(f\"  {full}: {sz:.1f} MB\" if sz > 0 else f\"  MISSING: {full}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f1d33",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 — Build Vocabulary\n",
    "\n",
    "Xây dựng:\n",
    "- **Question vocabulary**: các từ xuất hiện >= 3 lần trong training questions\n",
    "- **Answer vocabulary**: các câu trả lời xuất hiện >= 5 lần\n",
    "\n",
    "Output:\n",
    "- `data/processed/vocab_questions.json`\n",
    "- `data/processed/vocab_answers.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3145d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/scripts/1_build_vocab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59448812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra vocab đã tạo\n",
    "import json\n",
    "\n",
    "with open('data/processed/vocab_questions.json') as f:\n",
    "    vq = json.load(f)\n",
    "with open('data/processed/vocab_answers.json') as f:\n",
    "    va = json.load(f)\n",
    "\n",
    "print(f\"Question vocab size: {len(vq['word2idx'])}\")\n",
    "print(f\"Answer vocab size  : {len(va['word2idx'])}\")\n",
    "print(f\"\\nSample question words: {list(vq['word2idx'].keys())[:15]}\")\n",
    "print(f\"Sample answer words  : {list(va['word2idx'].keys())[:15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d13083",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Train All 4 Models\n",
    "\n",
    "Train lần lượt 4 kiến trúc:\n",
    "\n",
    "| Model | Encoder | Attention | Đặc điểm |\n",
    "|-------|---------|-----------|----------|\n",
    "| A | Scratch CNN (5 conv blocks) | No | Baseline, train từ đầu |\n",
    "| B | ResNet101 (pretrained, frozen) | No | Transfer learning |\n",
    "| C | Scratch CNN Spatial (7×7=49 regions) | Bahdanau | Attention trên scratch features |\n",
    "| D | ResNet101 Spatial (pretrained, frozen) | Bahdanau | Attention trên pretrained features |\n",
    "\n",
    "**Hyperparameters:**\n",
    "- `embed_size=512`, `hidden_size=1024`, `num_layers=2`\n",
    "- `lr=1e-3`, `batch_size=128`, `epochs=10`\n",
    "- AMP (mixed precision) tự bật trên GPU\n",
    "- ReduceLROnPlateau (factor=0.5, patience=2)\n",
    "- Gradient clipping (max_norm=5.0)\n",
    "\n",
    "**Output mỗi model:**\n",
    "- `checkpoints/model_X_epoch{1..10}.pth` — per-epoch checkpoint\n",
    "- `checkpoints/model_X_best.pth` — checkpoint tốt nhất (lowest val loss)\n",
    "- `checkpoints/model_X_resume.pth` — full checkpoint để resume\n",
    "- `checkpoints/history_model_X.json` — train/val loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model A: Scratch CNN, No Attention\n",
    "!python src/train.py --model A --epochs 10 --lr 1e-3 --batch_size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model B: ResNet101 (pretrained, frozen), No Attention\n",
    "!python src/train.py --model B --epochs 10 --lr 1e-3 --batch_size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model C: Scratch CNN Spatial, Bahdanau Attention\n",
    "!python src/train.py --model C --epochs 10 --lr 1e-3 --batch_size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model D: ResNet101 Spatial (pretrained, frozen), Bahdanau Attention\n",
    "!python src/train.py --model D --epochs 10 --lr 1e-3 --batch_size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04679148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra checkpoints đã lưu\n",
    "import os\n",
    "print(\"Saved checkpoints:\")\n",
    "for f in sorted(os.listdir('checkpoints')):\n",
    "    sz = os.path.getsize(f'checkpoints/{f}') / 1e6\n",
    "    print(f\"  {f:45s} {sz:8.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4680ea0",
   "metadata": {},
   "source": [
    "### (Optional) Fine-tuning Model B, D với CNN unfreeze\n",
    "\n",
    "Sau khi train 10 epochs với ResNet frozen, có thể tiếp tục fine-tune bằng cách:\n",
    "- Unfreeze layer3 + layer4 của ResNet\n",
    "- Dùng learning rate nhỏ hơn cho backbone (`cnn_lr_factor=0.1`)\n",
    "\n",
    "Điều này giúp ResNet adapt features cho VQA thay vì chỉ dùng ImageNet features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb009614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Fine-tune Model B: resume + unfreeze backbone\n",
    "# !python src/train.py --model B --epochs 5 --lr 5e-4 --batch_size 128 \\\n",
    "#     --resume checkpoints/model_b_resume.pth --finetune_cnn --cnn_lr_factor 0.1\n",
    "\n",
    "# (Optional) Fine-tune Model D: resume + unfreeze backbone\n",
    "# !python src/train.py --model D --epochs 5 --lr 5e-4 --batch_size 128 \\\n",
    "#     --resume checkpoints/model_d_resume.pth --finetune_cnn --cnn_lr_factor 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48264d56",
   "metadata": {},
   "source": [
    "### (Optional) Scheduled Sampling\n",
    "\n",
    "Giảm **exposure bias** (mismatch giữa teacher forcing training vs autoregressive inference):\n",
    "- Epoch đầu: chủ yếu dùng ground-truth token (epsilon ≈ 1)\n",
    "- Epoch cuối: chủ yếu dùng model's own prediction (epsilon → 0)\n",
    "- Schedule: `epsilon = k / (k + exp(epoch/k))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Train với Scheduled Sampling\n",
    "# !python src/train.py --model A --epochs 10 --lr 1e-3 --batch_size 128 --scheduled_sampling --ss_k 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efbb05",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 — Plot Training Curves\n",
    "\n",
    "So sánh train/val loss của 4 models qua các epochs.\n",
    "\n",
    "Output: `checkpoints/training_curves.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/plot_curves.py --models A,B,C,D --output checkpoints/training_curves.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị training curves\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename='checkpoints/training_curves.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a4aa9",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5 — Evaluate từng Model\n",
    "\n",
    "Đánh giá mỗi model trên **validation set** với các metrics:\n",
    "- **VQA Accuracy**: `min(matching_annotations / 3, 1.0)` — official VQA metric\n",
    "- **Exact Match**: prediction == ground truth (strict)\n",
    "- **BLEU-1, BLEU-2, BLEU-3, BLEU-4**: n-gram overlap\n",
    "- **METEOR**: synonym-aware matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model A\n",
    "!python src/evaluate.py --model_type A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572915e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model B\n",
    "!python src/evaluate.py --model_type B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model C\n",
    "!python src/evaluate.py --model_type C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model D\n",
    "!python src/evaluate.py --model_type D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0b481",
   "metadata": {},
   "source": [
    "### (Optional) Evaluate với Beam Search\n",
    "\n",
    "Thay vì greedy decode (chọn token xác suất cao nhất), beam search giữ top-k candidates tại mỗi bước để tìm sequence tốt hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55761ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Evaluate với beam search width=3\n",
    "# !python src/evaluate.py --model_type D --beam_width 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cde939",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 — So sánh 4 Models (Comparison Table)\n",
    "\n",
    "So sánh tất cả models trên cùng validation set, in bảng side-by-side.\n",
    "\n",
    "Đây là phần **đánh giá chính** của bài — so sánh:\n",
    "- Scratch vs Pretrained (A vs B, C vs D)\n",
    "- No Attention vs Attention (A vs C, B vs D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/compare.py --models A,B,C,D --epoch 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b55d5a",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 — Single-Sample Inference\n",
    "\n",
    "Chạy inference trên 1 sample cụ thể để xem model sinh câu trả lời như thế nào.\n",
    "\n",
    "Script `inference.py` mặc định chạy model A trên sample đầu tiên. Có thể sửa trực tiếp trong code nếu muốn đổi model/sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d396b98",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8 — Attention Visualization (Model C, D)\n",
    "\n",
    "Trực quan hóa cơ chế attention:\n",
    "- Với mỗi token được sinh ra, hiển thị **heatmap** trên ảnh gốc cho thấy vùng nào model đang \"nhìn vào\"\n",
    "- Attention weights `alpha` có shape `(49,)` → reshape thành `7×7` → upsample lên `224×224`\n",
    "\n",
    "Output: `checkpoints/attn_model_c.png`, `checkpoints/attn_model_d.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention visualization — Model C\n",
    "!python src/visualize.py --model_type C --sample_idx 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56294ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention visualization — Model D\n",
    "!python src/visualize.py --model_type D --sample_idx 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf774c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị attention maps\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "for mt in ['c', 'd']:\n",
    "    path = f'checkpoints/attn_model_{mt}.png'\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\\n--- Model {mt.upper()} Attention ---\")\n",
    "        display(Image(filename=path))\n",
    "    else:\n",
    "        print(f\"Not found: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554207b",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Step | Script | Output |\n",
    "|------|--------|--------|\n",
    "| Build Vocab | `src/scripts/1_build_vocab.py` | `data/processed/vocab_*.json` |\n",
    "| Train | `src/train.py --model X` | `checkpoints/model_X_epoch*.pth`, `history_model_X.json` |\n",
    "| Plot Curves | `src/plot_curves.py` | `checkpoints/training_curves.png` |\n",
    "| Evaluate | `src/evaluate.py --model_type X` | Printed metrics |\n",
    "| Compare | `src/compare.py` | Side-by-side comparison table |\n",
    "| Inference | `src/inference.py` | Question + Predicted answer |\n",
    "| Attention | `src/visualize.py --model_type C/D` | `checkpoints/attn_model_*.png` |\n",
    "\n",
    "### Kiến trúc\n",
    "\n",
    "```\n",
    "Image ──> CNN Encoder ──> img_feature ──┐\n",
    "                                        ├── Hadamard Fusion ──> h_0 ──> LSTM Decoder ──> Answer tokens\n",
    "Question ──> LSTM Encoder ──> q_feature ─┘         ↑\n",
    "                                          (Model C,D: Bahdanau Attention\n",
    "                                           attends over 49 spatial regions)\n",
    "```\n",
    "\n",
    "### Kết quả đánh giá\n",
    "\n",
    "_(Xem output Step 6 ở trên để điền bảng kết quả)_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
